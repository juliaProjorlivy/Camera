
# Camera project

Идея проекта заключалась в том, чтобы создать камеру, реагирующую на движение. В итоговом варианте камера реагирует на синий цвет, а также может двигаться с помощью пульта. Мозгом нашего проекта стала [Raspberry pi 4](https://www.raspberrypi.com/documentation/computers/raspberry-pi.html) с камерой [Camera Module 3.](https://www.raspberrypi.com/products/camera-module-3/)  Чтобы камера была подвижной по осям Ox и Oy, мы использовали два [сервопривода](https://docs.sunfounder.com/projects/ultimate-sensor-kit/en/latest/components_basic/27-component_servo.html). Для включения/выключения камеры и её управления был задействован [ИК-приемник,](https://roboshop.spb.ru/sensors/infrakrasnye-datchiki/tl1838), управляемый [Arduino Nano](https://3d-diy.ru/blog/arduino-nano/?srsltid=AfmBOoobsfLvRHXmztk4oDekqijM6OquVmeA1C7HS3Jm3zs6FXj-3EUY).

![project_image](images/project_photo.jpg)

![project_gif](./images/project_usage.gif)

# Настройка Raspberry pi

## Установка OS и VNC

Накатили Raspberry pi OS (все необходимое можно найти
[здесь](https://www.raspberrypi.com/software/)).
Советую сразу настроить удаленный доступ к графическому интерфейсу
[VNC для удобной работы с малинкой.](https://habr.com/ru/sandbox/148360/)

## Настройка виртуального окружения для работы с python

Для нормальной работы с библиотекой picamra2 лучше установить виртуальное окружение:

```sh
sudo apt install python3-venv
python3 -m venv —system-site-packages env
```

Для активации:

```sh
source env/bin/activate
```

Соответственно, чтобы выйти из окружения: `deactivate`.  
Для работы с пинами малинки использовали библиотеку [pigpio](https://abyz.me.uk/rpi/pigpio/pigpiod.html), для работы с которой нужно запустить pigpio library as a daemon:

```sh
sudo pigpiod
```

## Настройка ИК-приемника

## ИК-приемник на Raspberry pi (LIRC)

Вообще говоря, сначала мы пытались обрабатывать кнопки всё так же на малинке через библиотеку LIRC. Нужно было немного изменить конфиг малинки, добавив несколько строчек в него ([вот здесь всё детально расписано](https://www.instructables.com/Setup-IR-Remote-Control-Using-LIRC-for-the-Raspber/)).

Схему подключения ИК-приёмника к малинке не буду вставлять — тут всё просто: GND к GND, VCC к 3.3V, OUT к, например, 18 порту малинки (GPIO18 имеет альтернативную функцию **PCM_CLK**, которая позволяет использовать аппаратный PWM, что критично для стабильного декодирования ИК-сигналов).

Проверяем, что ИК-приёмник работает:

```sh
mode2 -d /dev/lirc0
```

Если на экран выводится **pulse/space codes**, то всё круто — работает.
Второй шаг — найти конфиг для нашего пульта. У нас это обычный китайский пульт Car MP3.

![remote_image](images/remote_photo.png)


Но внимание! В общем [архиве](https://lirc.sourceforge.net/remotes/) не нашлось конфига! Однако мы не отчаялись. В таком случае можно вручную записать свой конфиг, используя утилиту irrecord. Как и было написано в указанной ранее [статье](https://www.instructables.com/Easy-Setup-IR-Remote-Control-Using-LIRC-for-the-Ra/): "I was VERY unsuccessful trying to create a file using this utility despite much effort". 
Разочаровавшись, мы пошли вглубь интернета с целью всё-таки найти конфиг под наш пульт. Если кому-то понадобится, ссылка есть на [этом сайте](https://elchupanibrei.livejournal.com/43594.html) рядом с изображением пульта.
Добавляем наш конфиг в `/etc/lirc/lircd.conf.d/` и включаем его в `/etc/lirc/lircd.conf`:

```sh
mv carMP3.conf /etc/lirc/lircd.conf.d/
sudo echo 'include "lircd.conf.d/*.conf"' >> /etc/lirc/lircd.conf 
```

Перезапускаем LIRC и проверяем работает ли конфиг для пульта:

```sh
sudo service lirc start
irw /var/run/lirc/lircd
```

После нажатия на кнопку пульта должно выводиться что-то типа:

```sh
0000000000ffb04f 00 KEY_200+ carMP3.conf
```

Проделываем те же махинации, что и в статье, за исключением содержания irexec.lircrc — его делаем своим. Итак, после перезапуска малинки кнопка пульта должна была выполнить указанные в irexec.lircrc команды, но ничего опять не получилось. Я даже проверяла логи:

```sh
sudo journalctl -u lircd -n 50 --no-pager
```

Но ошибки, вроде бы, и не было, однако ничего не работало как надо. Поэтому было принято стратегическое решение воспользоваться Arduino для работы с пультом — так оказалось в разы проще.

## ИК-приемник и arduino nano

Итак, перед нами цель — сделать так, чтобы Arduino принимала сигналы с ИК-приёмника и отправляла название кнопки через Serial-порт на малинку.
Готовый скетч для этого уже есть в интернете: [https://newbiely.com/tutorials/arduino-nano/arduino-nano-ir-remote-control](https://newbiely.com/tutorials/arduino-nano/arduino-nano-ir-remote-control). Я его впоследствии немного адаптировала под свои нужды (об этом подробнее позже). 
Краткий алгоритм действий:

1. Загружаем скетч на Arduino
2. Проверяем через Serial Monitor корректность отображения нажатий кнопок пульта
3. Подключаем собранную схему к Raspberry Pi (не забываем про USB-кабель)

![circuit_image](images/circuit_image.png)

## Написание кода

### Код для камеры и сервоприводов

В изначальном варианте мы хотели использовать YOLO как модель компьютерного зрения для обнаружения объектов (в частности, людей). Однако малинка работала исключительно медленно, поэтому мы отказались от этой идеи. Вместо этого наша камера детектит объекты синего цвета и, соответственно, движется в их сторону. Для анализа изображений мы используем библиотеку OpenCV. Код с YOLO и наш код лежат в исходниках.

### Как arduino взаимодействует с Raspberry pi

Внутри основной программы создаются два потока выполнения:

1. Первый поток отвечает за:
   - Обработку изображений с камеры
   - Поиск координат центра обнаруженного объекта
   - Управление сервоприводами
2. Второй поток выполняет:
   - Ожидание сигналов через Serial-порт от Arduino
   - Обработку нажатий кнопок пульта

Взаимодействие между потоками организовано через очередь сообщений. Исходный код доступен в файле `src/arduino.py`.

## Включение камеры по пульту

Теперь необходимо реализовать включение камеры (запуск Python-скрипта) по нажатию кнопки на пульте. Для этого мы можем использовать следующий подход:

1. Arduino при старте подаёт высокий сигнал на определённый GPIO-пин
   - Для этого потребуется модификация существующего скетча
2. Raspberry Pi должен:
   - Детектировать этот сигнал через GPIO
   - Запускать основной Python-скрипт обработки

Основные технические сложности реализации:

1. Требуется дополнительный скрипт, который должен:
   - Автозапускаться при включении Raspberry Pi
   - Ожидать сигнал на GPIO-пине
2. Необходима автоматическая активация демона pigpiod при старте системы:
   - Для корректной работы библиотеки pigpio

Это все довольно легко решается с помощью [Cron](https://timeweb.com/ru/community/articles/chto-takoe-cron).

```sh
sudo crontab -e
```

Добавляем следующую строчку в конец и перезапускаемся:

```sh
@reboot /home/pi/env/bin/python3 /home/pi/listener.py > log_listener.txt 2>&1
```

где listener.py - скрипт, ожидающий сигнала. Теперь при включении малинки, запускается listener.py на заднем фоне.  Это можно проверить:

```sh
ps aux | grep python
```

При получении сигнала listener.py запускает еще один скрипт - awake.sh, который лишь запускает демона pigpio и основную прогу.

# Создание корпуса и работа с 3D принтером

  Главной задачей было обеспечить подвижность камеры во всех направлениях и добиться органичного расположения всех компонент сборки в пространстве. За счёт отсутствия некоторых особенностей камеры и raspberry pi в 3D моделях из интернета, некоторые измерения были произведены вручную и отражены на 3D деталях, что приводило к неточностям в сборке. В итоге, благодаря клею и напильникам, все вылившиеся в физической форме недочёты были устранены и отлажены под оборудование.

  Главной проблемой была разработка надёжного сцепления крепежа и деталей, т. к. винты, предназначенные для сервоприводов и камеры, либо отсутствовали, либо не соответствовали нашим требованиям (ненадёжно вкручивались в пластик за счёт своей малой длины). Эта проблема была решена за счёт подбора размеров и форм 3D деталей, обеспечивающих большую площадь соприкосновения и удерживающих конструкцию с помощью силы трения.

   Итоговая конструкция позволяет реализовывать все запрограммированные функции системы и обеспечивает надёжную связку и свободную эксплуатацию всех компонент.
